{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80mXvCfwVQDy",
        "outputId": "6a1f04e6-3614-4584-c5db-eb5bf08863bb"
      },
      "source": [
        "! pip install spacy\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ckIkf-BVUQZ",
        "outputId": "ff417679-ec92-499c-91dc-b59e37e5a709"
      },
      "source": [
        "!pip install pickle\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-w6pyrWVcZf"
      },
      "source": [
        "import spacy\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8yck7eaV-P1"
      },
      "source": [
        "train_data=pickle.load(open('train_data.pkl','rb'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bys14g7pWH42",
        "outputId": "9586b3b1-df61-43ca-e5c9-0c0a3b40732c"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [(1749, 1755, 'Companies worked at'),\n",
              "   (1696, 1702, 'Companies worked at'),\n",
              "   (1417, 1423, 'Companies worked at'),\n",
              "   (1356, 1793, 'Skills'),\n",
              "   (1209, 1215, 'Companies worked at'),\n",
              "   (1136, 1248, 'Skills'),\n",
              "   (928, 932, 'Graduation Year'),\n",
              "   (858, 889, 'College Name'),\n",
              "   (821, 856, 'Degree'),\n",
              "   (787, 791, 'Graduation Year'),\n",
              "   (744, 750, 'Companies worked at'),\n",
              "   (722, 742, 'Designation'),\n",
              "   (658, 664, 'Companies worked at'),\n",
              "   (640, 656, 'Designation'),\n",
              "   (574, 580, 'Companies worked at'),\n",
              "   (555, 573, 'Designation'),\n",
              "   (470, 493, 'Companies worked at'),\n",
              "   (444, 469, 'Designation'),\n",
              "   (308, 314, 'Companies worked at'),\n",
              "   (234, 240, 'Companies worked at'),\n",
              "   (175, 198, 'Companies worked at'),\n",
              "   (93, 137, 'Email Address'),\n",
              "   (39, 48, 'Location'),\n",
              "   (13, 38, 'Designation'),\n",
              "   (0, 12, 'Name')]})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OTmMEJTWL2A"
      },
      "source": [
        "nlp = spacy.blank('en')\n",
        "\n",
        "def train_model(train_data):\n",
        "    if 'ner' not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe('ner')\n",
        "        nlp.add_pipe(ner,last=True)\n",
        "\n",
        "    for _,annotation in train_data:\n",
        "        for ent in annotation['entities']:\n",
        "            ner.add_label(ent[2])\n",
        "\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe!='ner']\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(10):\n",
        "            print(\"statring iteration\"+str(itn))\n",
        "            random.shuffle(train_data)\n",
        "            losses={}\n",
        "            index=0\n",
        "            for text, annotation in train_data:\n",
        "                try:\n",
        "                    nlp.update(\n",
        "                        [text],\n",
        "                        [annotation],\n",
        "                        drop=0.2,\n",
        "                        sgd=optimizer,\n",
        "                        losses=losses\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "            print(losses)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghUPkksAWgYZ",
        "outputId": "4c0139b2-2ae2-495f-ea10-63ed1d5512b9"
      },
      "source": [
        "train_model(train_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "statring iteration0\n",
            "{'ner': 14055.21030717858}\n",
            "statring iteration1\n",
            "{'ner': 9274.412201082749}\n",
            "statring iteration2\n",
            "{'ner': 13552.84029592536}\n",
            "statring iteration3\n",
            "{'ner': 11135.33115240316}\n",
            "statring iteration4\n",
            "{'ner': 6452.7820318525055}\n",
            "statring iteration5\n",
            "{'ner': 5625.124968738723}\n",
            "statring iteration6\n",
            "{'ner': 5874.7114674226905}\n",
            "statring iteration7\n",
            "{'ner': 6088.86420539147}\n",
            "statring iteration8\n",
            "{'ner': 4589.012681197585}\n",
            "statring iteration9\n",
            "{'ner': 5271.835250850755}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCoHcDC6WjM8"
      },
      "source": [
        "nlp.to_disk('nlp_model')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcxIQJQNXnWj"
      },
      "source": [
        "nlp_model=spacy.load('nlp_model')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa7-wOcwX2qr",
        "outputId": "53c63b06-83d6-4ccd-d11a-810844a1c444"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Pradeeba V LEAD ENGINEER - CISCO  - Email me on Indeed: indeed.com/r/Pradeeba-V/19ff20f4b8552375  WORK EXPERIENCE  LEAD ENGINEER  CISCO -  June 2014 to Present  PROJECT SPECIFIC SKILLS JAVASCRIPT, OOJS, HTML5, CSS3, REST, DOJO, Angular JS TOOLS USED SVN, Code Collaborator Description:  Cisco Prime Infrastructure simplifies the management of wireless and wired networks. The Prime UI offers Prime Widget Toolkit (XWT) which provides dojo widgets. The UI supports HTML 5 features. The Prime UI offers rich UI experience which includes consistency, better look and feel and scalable designs to handle large volume of data.  Responsibilities: • Creating Widgets in dojo • Enhancement of existing widget • Handling REST calls • Writing Test cases • Unit Testing  2. Project Title FINUX  INDUSTRY FINACLE - BANKING  SENIOR SYSTEMS ENGINEER  -  June 2012 to June 2014  PROJECT SPECIFIC SKILLS JAVASCRIPT, DOJO, CSS, HTML  Description: Finacle is a core banking software package. It is used by multiple banks across several countries, it can handle multi-currency transactions.  https://www.indeed.com/r/Pradeeba-V/19ff20f4b8552375?isid=rex-download&ikw=download-top&co=IN   To achieve the common look and feel for all the screens where the interaction done with the user in the form of getting input values as well as retrieval of some kind of data and display of such data. I was totally involved in developing the Datagrid UI component in DOJO to display the search results which are obtained as a result of inquiring the transactions.  Responsibilities: • Front end enhancements for the Core product. • Discussing and finalizing the end UI screens with Functional and Design teams. • Writing front end and back end validation routines. • Regression testing for menus using Service Testing Framework. 3. Project Title FINACLE  INDUSTRY BANKING CLIENT Universal Banking Product from INFOSYS  SYSTEMS ENGINEER  -  October 2011 to May 2012  PROJECT SPECIFIC SKILLS JAVASCRIPT, DOJO, CSS, HTML  Description: Finacle is a core banking software package. It is used by multiple banks across several countries, it can handle multi-currency transactions. Being a part of Finacle team, I had involved in making the front end enhancement for Core product. Responsibilities:  • Front end enhancements for the Core product. • Bug Fixing  EDUCATION  B.Tech  Institute of Road and Transport May  October 1980  ADDITIONAL INFORMATION  TECHNICAL SKILLS Programming Languages: Core Java Scripting languages: JavaScript, OOJS Databases: Oracle Operating systems: Windows (7, XP) and UNIX Tools & Utilities: Eclipse, SSH, WinSCP, Code Collaborator, SVN    Web Designing Tools: HTML 4, HTML 5, CSS 3, DOJO, Angular JS Web Service: REST Web services',\n",
              " {'entities': [(2707, 2711, 'Skills'),\n",
              "   (2683, 2693, 'Skills'),\n",
              "   (2677, 2681, 'Skills'),\n",
              "   (2670, 2673, 'Skills'),\n",
              "   (2662, 2666, 'Skills'),\n",
              "   (2654, 2658, 'Skills'),\n",
              "   (2626, 2629, 'Skills'),\n",
              "   (2607, 2624, 'Skills'),\n",
              "   (2599, 2605, 'Skills'),\n",
              "   (2594, 2597, 'Skills'),\n",
              "   (2585, 2592, 'Skills'),\n",
              "   (2561, 2565, 'Skills'),\n",
              "   (2541, 2556, 'Skills'),\n",
              "   (2515, 2521, 'Skills'),\n",
              "   (2499, 2503, 'Skills'),\n",
              "   (2487, 2497, 'Skills'),\n",
              "   (2456, 2465, 'Skills'),\n",
              "   (2386, 2390, 'Graduation Year'),\n",
              "   (2341, 2376, 'College Name'),\n",
              "   (2333, 2340, 'Degree'),\n",
              "   (1982, 1986, 'Skills'),\n",
              "   (1977, 1980, 'Skills'),\n",
              "   (1971, 1975, 'Skills'),\n",
              "   (1959, 1969, 'Skills'),\n",
              "   (1888, 1904, 'Designation'),\n",
              "   (1824, 1840, 'Designation'),\n",
              "   (1436, 1440, 'Skills'),\n",
              "   (1085, 1125, 'Email Address'),\n",
              "   (911, 915, 'Skills'),\n",
              "   (906, 909, 'Skills'),\n",
              "   (900, 904, 'Skills'),\n",
              "   (888, 898, 'Skills'),\n",
              "   (819, 835, 'Designation'),\n",
              "   (812, 835, 'Designation'),\n",
              "   (784, 810, 'Designation'),\n",
              "   (712, 716, 'Skills'),\n",
              "   (464, 468, 'Skills'),\n",
              "   (255, 272, 'Skills'),\n",
              "   (250, 253, 'Skills'),\n",
              "   (228, 238, 'Skills'),\n",
              "   (222, 226, 'Skills'),\n",
              "   (216, 220, 'Skills'),\n",
              "   (210, 214, 'Skills'),\n",
              "   (210, 213, 'Skills'),\n",
              "   (203, 208, 'Skills'),\n",
              "   (203, 207, 'Skills'),\n",
              "   (197, 201, 'Skills'),\n",
              "   (185, 195, 'Skills'),\n",
              "   (130, 135, 'Companies worked at'),\n",
              "   (115, 128, 'Designation'),\n",
              "   (56, 96, 'Email Address'),\n",
              "   (27, 32, 'Companies worked at'),\n",
              "   (11, 24, 'Designation'),\n",
              "   (0, 10, 'Name')]})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivmFxqRDX5x5",
        "outputId": "35fe9b43-721c-420d-c68e-4925fdb55cce"
      },
      "source": [
        "doc = nlp_model(train_data[0][0])\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(f'{ent.label_.upper():{30}} - {ent.text}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                           - Pradeeba V\n",
            "DESIGNATION                    - LEAD ENGINEER\n",
            "COMPANIES WORKED AT            - CISCO\n",
            "EMAIL ADDRESS                  - indeed.com/r/Pradeeba-V/19ff20f4b8552375\n",
            "DESIGNATION                    - LEAD ENGINEER\n",
            "COMPANIES WORKED AT            - CISCO\n",
            "COLLEGE NAME                   - SENIOR SYSTEMS ENGINEER\n",
            "COMPANIES WORKED AT            - INFOSYS\n",
            "DEGREE                         - B.Tech\n",
            "COLLEGE NAME                   - Institute of Road and Transport May\n",
            "SKILLS                         - Programming Languages: Core Java Scripting languages: JavaScript, OOJS Databases: Oracle Operating systems: Windows (7, XP) and UNIX Tools & Utilities: Eclipse, SSH, WinSCP, Code Collaborator, SVN    Web Designing Tools: HTML 4, HTML 5, CSS 3, DOJO, Angular JS Web Service: REST Web services\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AndMS8nfYpOK",
        "outputId": "14727940-f60c-4414-8610-31865b22fd18"
      },
      "source": [
        "!pip install PyMuPDF"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.18.19-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 4.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDneMiXdY-Eo",
        "outputId": "2e57ec2b-b5c4-45b8-9d35-ef3c7975b5c8"
      },
      "source": [
        "import sys\n",
        "import fitz\n",
        "fname ='Shashi_CV.pdf'\n",
        "doc = fitz.open(fname)\n",
        "text =\"\"\n",
        "for page in doc:\n",
        "    text =text + str(page.getText())\n",
        "\n",
        "tx= \" \".join(text.split('/n'))\n",
        "print(text)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHASHI PRABHA SAHU\n",
            "Contact- +91-8839756423\n",
            "|\n",
            "Email-shashiprabhasahu23@gmail.com\n",
            "|\n",
            "EDUCATION\n",
            "• B.Tech, Information Technology, KIIT University, 2020 CGPA-8.2\n",
            "WORK EXPERIENCE\n",
            "Black Knight Financial Services\n",
            "Data Analyst, December 2020 to April 2021, Full-Time\n",
            "• Involved in analysing,designing, development, implementation, quality checking and curating data.\n",
            "• Used backend technologies such as SQL, C#, Python for storing and retrieving data.\n",
            "• Scrapped and manipulated data from diﬀerent source using SQL.\n",
            "• Done analysis on factors inﬂuencing the prices such as tax related data, property data etc for diﬀerent type of counties.\n",
            "Reliance Jio\n",
            "Software Developer, June 2021 to Present, Full-Time\n",
            "• Adopted the MicroService Architecture pattern and worked with teams on MERN stack.\n",
            "• Actively involved in project delivery for various verticals (Health, Procurement, Finance etc) using the AGILE method-\n",
            "ology.\n",
            "• Scrapped and manipulated data from diﬀerent source using SQL.\n",
            "• Use mongoDB for connecting the servers.\n",
            "INTERNSHIP\n",
            "DAWN, IIT Kharagpur\n",
            "Deep Learning Intern, January 2019 to June 2019\n",
            "• Implement WideResnet Deeplearning Model to classify diﬀerent plants disease.\n",
            "• Achieved accuracy 90% on nodules data with class imbalance of 1:1 with just depth of 10 and widening factor of 5.\n",
            "• Find the similarity between the two images by adopting feature vectors using lhash,phash algorithms.\n",
            "• Experimented with trained models such as VGG, 2D-Resnet, Squeezenet for extracting the feature vectors of images.\n",
            "• Achieved 91% sensitivity for nodules and 90% accuracy using novel Focal Loss Method for an inbalance class of 1:10.\n",
            "PROJECTS\n",
            "Combined ARMA-Neural Network Models to Predict Stock Prices\n",
            "• Compared the ARMA model with the state-of-the-art neural networks for stock price forecasting\n",
            "• Applied two datasets Tadawul All Share Index (TASI) and Dow Jones Industrial Average(DJI) for the prediction of stock\n",
            "prices.\n",
            "• Reduced MAPE from 2.21% to 1.46% and 16.12% to 2.5% on prediction on both datasets by using best( w.r.t MAPE)\n",
            "neural model than ARMA model.\n",
            "Smartphone Application for Banking Technology\n",
            "• Worked on Banking Chatbot Development for Android Smartphones using Dialogﬂow, Rasa NLU.\n",
            "• Assemble and conﬁgure a backend server using Node.JS. App provides 24/7 online customer support to bank users.\n",
            "• Build a RESTful API for the front-end to access backend services for testing. The bot is trained on the 4000 queries.\n",
            "Stock Prediction using Explainable AI\n",
            "• Reﬁned LSTM model using technical indicators to predict future price and to predict daily change in prices.\n",
            "• Rigorously doing literature survey on mathematical, probabilistic which helps in predicting future stock prices.\n",
            "• Implore LRP by assign relevance scores to input variables which predict deep neural-networks.\n",
            "Machine Learning\n",
            "• Evolved the Decision Tree algorithm in python to solve a real-world classiﬁcation problem with diﬀerent gain metrics.\n",
            "• Implemented a Multilayer Neural Network in python to classify a messages as SPAM.\n",
            "Online Quiz system ‘Technical Quiz’\n",
            "• Developed an Android App named ‘Technical Quiz’ which provides online based quiz with multiple choice question.\n",
            "• Quiz application will support android base operating system. With this application, users or any organization can per-\n",
            "form actions like Administrative Task and Interview Task.\n",
            "Project on text based sentiment Analysis using Naive Bayes Classiﬁer\n",
            "• Objective: Detect Human sentiments whether it is positive, negative or neutral using naive bayes classiﬁer.\n",
            "• Tokenized the data followed by cleaning involving removal of stop words and pre-processing text data to perform feature\n",
            "extraction using methods like natural language toolkit.\n",
            "• Classiﬁed data using supervised learning to calculate polarity of statement whether positive, negative or neutral.\n",
            "TECHNICAL SKILLS\n",
            "• Programming Languages-C#, Java, SQL Server, Python, .Net core, C++, R | Fields-Machine Learning, AI, Data Science |\n",
            "Software and Frameworks - Tableau, Node.js, Flutter, Dart, React.js, MongoDB\n",
            "COURSEWORK INFORMATION\n",
            "Database Management System, Operating System , Machine Learning, Artiﬁcial intelligence, Discrete Structures, Algo-\n",
            "rithms and Data Structures, C Programming, Probability and Statistics, Financial Modelling\n",
            "AWARDS\n",
            "• Amongst top 50 student selected for India’s best engineering students, Economic Times appeared by 50,000 students.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAk3NwzHZRo_",
        "outputId": "bde8d85c-0978-4168-82be-57e51c30e834"
      },
      "source": [
        "doc = nlp_model(tx)\n",
        "for ent in doc.ents:\n",
        "  print(f'{ent.label_.upper():{30}} - {ent.text}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                           - SHASHI PRABHA\n",
            "NAME                           - SAHU\n",
            "\n",
            "SKILLS                         - • B.Tech, Information Technology, KIIT University, 2020 CGPA-8.2\n",
            "WORK EXPERIENCE\n",
            "Black Knight Financial Services\n",
            "Data Analyst, December 2020 to April 2021, Full-Time\n",
            "• Involved in analysing,designing, development, implementation, quality checking and curating data.\n",
            "• Used backend technologies such as SQL, C#, Python for storing and retrieving data.\n",
            "• Scrapped and manipulated data from diﬀerent source using SQL.\n",
            "• Done analysis on factors inﬂuencing the prices such as tax related data, property data etc for diﬀerent type of counties.\n",
            "Reliance Jio\n",
            "Software Developer, June 2021 to Present, Full-Time\n",
            "• Adopted the MicroService Architecture pattern and worked with teams on MERN stack.\n",
            "• Actively involved in project delivery for various verticals (Health, Procurement, Finance etc) using the AGILE method-\n",
            "ology.\n",
            "• Scrapped and manipulated data from diﬀerent source using SQL.\n",
            "• Use mongoDB for connecting the servers.\n",
            "INTERNSHIP\n",
            "DAWN, IIT Kharagpur\n",
            "Deep Learning Intern, January 2019 to June 2019\n",
            "• Implement WideResnet Deeplearning Model to classify diﬀerent plants disease.\n",
            "• Achieved accuracy 90% on nodules data with class imbalance of 1:1 with just depth of 10 and widening factor of 5.\n",
            "• Find the similarity between the two images by adopting feature vectors using lhash,phash algorithms.\n",
            "• Experimented with trained models such as VGG, 2D-Resnet, Squeezenet for extracting the feature vectors of images.\n",
            "• Achieved 91% sensitivity for nodules and 90% accuracy using novel Focal Loss Method for an inbalance class of 1:10.\n",
            "PROJECTS\n",
            "Combined ARMA-Neural Network Models to Predict Stock Prices\n",
            "• Compared the ARMA model with the state-of-the-art neural networks for stock price forecasting\n",
            "• Applied two datasets Tadawul All Share Index (TASI) and Dow Jones Industrial Average(DJI) for the prediction of stock\n",
            "prices.\n",
            "• Reduced MAPE from 2.21% to 1.46% and 16.12% to 2.5% on prediction on both datasets by using best( w.r.t MAPE)\n",
            "neural model than ARMA model.\n",
            "Smartphone Application for Banking Technology\n",
            "• Worked on Banking Chatbot Development for Android Smartphones using Dialogﬂow, Rasa NLU.\n",
            "• Assemble and conﬁgure a backend server using Node.JS. App provides 24/7 online customer support to bank users.\n",
            "• Build a RESTful API for the front-end to access backend services for testing. The bot is trained on the 4000 queries.\n",
            "Stock Prediction using Explainable AI\n",
            "• Reﬁned LSTM model using technical indicators to predict future price and to predict daily change in prices.\n",
            "• Rigorously doing literature survey on mathematical, probabilistic which helps in predicting future stock prices.\n",
            "• Implore LRP by assign relevance scores to input variables which predict deep neural-networks.\n",
            "Machine Learning\n",
            "• Evolved the Decision Tree algorithm in python to solve a real-world classiﬁcation problem with diﬀerent gain metrics.\n",
            "• Implemented a Multilayer Neural Network in python to classify a messages as SPAM.\n",
            "Online Quiz system ‘Technical Quiz’\n",
            "• Developed an Android App named ‘Technical Quiz’ which provides online based quiz with multiple choice question.\n",
            "• Quiz application will support android base operating system. With this application, users or any organization can per-\n",
            "form actions like Administrative Task and Interview Task.\n",
            "Project on text based sentiment Analysis using Naive Bayes Classiﬁer\n",
            "• Objective: Detect Human sentiments whether it is positive, negative or neutral using naive bayes classiﬁer.\n",
            "• Tokenized the data followed by cleaning involving removal of stop words and pre-processing text data to perform feature\n",
            "extraction using methods like natural language toolkit.\n",
            "• Classiﬁed data using supervised learning to calculate polarity of statement whether positive, negative or neutral.\n",
            "TECHNICAL SKILLS\n",
            "• Programming Languages-C#, Java, SQL Server, Python, .Net core, C++, R | Fields-Machine Learning, AI, Data Science |\n",
            "Software and Frameworks - Tableau, Node.js, Flutter, Dart, React.js, MongoDB\n",
            "COURSEWORK INFORMATION\n",
            "Database Management System, Operating System , Machine Learning, Artiﬁcial intelligence, Discrete Structures, Algo-\n",
            "rithms and Data Structures, C Programming, Probability and Statistics, Financial Modelling\n",
            "AWARDS\n",
            "• Amongst top 50 student selected for India’s best engineering students, Economic Times appeared by 50,000 students.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzruVyBVaiPa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}